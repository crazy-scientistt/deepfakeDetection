{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbde1889-aa43-4fa4-ad63-6e0cd48ada10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset created at: C:\\Users\\creat\\Downloads\\combined_dataset\n",
      "Total real videos: 1090\n",
      "Total fake videos: 1090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Paths\n",
    "celeb_real_path = r\"C:\\Users\\creat\\Downloads\\Celeb-DF-v2\\Celeb-real\"\n",
    "celeb_fake_path = r\"C:\\Users\\creat\\Downloads\\Celeb-DF-v2\\Celeb-synthesis\"\n",
    "ff_fake_path = r\"C:\\Users\\creat\\Downloads\\FF++\\fake\"\n",
    "ff_real_path = r\"C:\\Users\\creat\\Downloads\\FF++\\real\"\n",
    "\n",
    "output_dir = r\"C:\\Users\\creat\\Downloads\\combined_dataset\"\n",
    "os.makedirs(os.path.join(output_dir, \"real\"), exist_ok=True)  # Separate real folder\n",
    "os.makedirs(os.path.join(output_dir, \"fake\"), exist_ok=True)  # Separate fake folder\n",
    "\n",
    "# Function to copy and rename files into class-specific folders\n",
    "def copy_rename_videos(src_dir, dst_class_dir, label, start_id=0):\n",
    "    video_id = start_id\n",
    "    for filename in os.listdir(src_dir):\n",
    "        src_path = os.path.join(src_dir, filename)\n",
    "        if os.path.isfile(src_path):\n",
    "            ext = os.path.splitext(filename)[1]  # Preserve extension\n",
    "            new_name = f\"id_{video_id:04d}{ext}\"  # Format: id_0001.mp4 (label inferred from folder)\n",
    "            dst_path = os.path.join(dst_class_dir, new_name)\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            video_id += 1\n",
    "    return video_id  # Return next available ID\n",
    "\n",
    "# Step 1: Copy FF++ real videos (200) -> real/id_0000.mp4 to real/id_0199.mp4\n",
    "next_real_id = copy_rename_videos(ff_real_path, os.path.join(output_dir, \"real\"), \"real\", start_id=0)\n",
    "\n",
    "# Step 2: Copy Celeb-real (890) -> real/id_0200.mp4 to real/id_1099.mp4\n",
    "next_real_id = copy_rename_videos(celeb_real_path, os.path.join(output_dir, \"real\"), \"real\", start_id=next_real_id)\n",
    "\n",
    "# Step 3: Copy FF++ fake videos (200) -> fake/id_0000.mp4 to fake/id_0199.mp4\n",
    "next_fake_id = copy_rename_videos(ff_fake_path, os.path.join(output_dir, \"fake\"), \"fake\", start_id=0)\n",
    "\n",
    "# Step 4: Randomly select 400 Celeb-synthesis (fake) -> fake/id_0200.mp4 to fake/id_0599.mp4\n",
    "all_celeb_fake = os.listdir(celeb_fake_path)\n",
    "random.seed(42)\n",
    "selected_fake = random.sample(all_celeb_fake, 890)\n",
    "\n",
    "for filename in selected_fake:\n",
    "    src_path = os.path.join(celeb_fake_path, filename)\n",
    "    ext = os.path.splitext(filename)[1]\n",
    "    new_name = f\"id_{next_fake_id:04d}{ext}\"\n",
    "    dst_path = os.path.join(output_dir, \"fake\", new_name)\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "    next_fake_id += 1\n",
    "\n",
    "print(f\"Combined dataset created at: {output_dir}\")\n",
    "print(f\"Total real videos: {next_real_id}\")\n",
    "print(f\"Total fake videos: {next_fake_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb151c3a-f08b-49d8-b0ca-dbb964dde929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing real videos...\n",
      "Skipping id_0674: Not enough frames.\n",
      "Processing fake videos (limit: 1090 videos)...\n",
      "Done extracting frames.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Input paths\n",
    "input_base_path = r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\BothDatasets\\combined_dataset\"\n",
    "real_videos_path = os.path.join(input_base_path, \"real\")\n",
    "fake_videos_path = os.path.join(input_base_path, \"fake\")\n",
    "\n",
    "# Output paths\n",
    "output_base_path = r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\BothDatasets\\FramesExtracted\"\n",
    "real_output_path = os.path.join(output_base_path, \"RealFrames\")\n",
    "fake_output_path = os.path.join(output_base_path, \"FakeFrames\")\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(real_output_path, exist_ok=True)\n",
    "os.makedirs(fake_output_path, exist_ok=True)\n",
    "\n",
    "def extract_frames(video_path, output_folder, video_name, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames < num_frames:\n",
    "        print(f\"Skipping {video_name}: Not enough frames.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "    saved = 0\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i in frame_indices:\n",
    "            frame_filename = f\"{video_name}_frame{saved+1:02d}.jpg\"\n",
    "            frame_path = os.path.join(output_folder, frame_filename)\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            saved += 1\n",
    "    cap.release()\n",
    "\n",
    "# Process real videos\n",
    "print(\"Processing real videos...\")\n",
    "for video_file in os.listdir(real_videos_path):\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(real_videos_path, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        extract_frames(video_path, real_output_path, video_name)\n",
    "\n",
    "# Process fake videos, but only 590 of them\n",
    "print(\"Processing fake videos (limit: 1090 videos)...\")\n",
    "fake_video_count = 0\n",
    "fake_video_limit = 1090\n",
    "\n",
    "for video_file in os.listdir(fake_videos_path):\n",
    "    if fake_video_count >= fake_video_limit:\n",
    "        break\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(fake_videos_path, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        extract_frames(video_path, fake_output_path, video_name)\n",
    "        fake_video_count += 1\n",
    "\n",
    "print(\"Done extracting frames.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "344043c4-3492-4f0e-9f6e-45a66fa8ef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found 1 GPU(s):\n",
      " - PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if TensorFlow is detecting the GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(f\"✅ Found {len(gpus)} GPU(s):\")\n",
    "    for gpu in gpus:\n",
    "        print(f\" - {gpu}\")\n",
    "else:\n",
    "    print(\"❌ No GPU detected by TensorFlow.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d358b392-168f-457e-a8af-980c89d62a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Real frames with shuffling...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.30000000000000004 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 74\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Real frames with shuffling...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m real_groups \u001b[38;5;241m=\u001b[39m group_frames_by_video(real_frames_path)\n\u001b[1;32m---> 74\u001b[0m \u001b[43mshuffle_split_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreal_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreal_frames_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_base_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_base_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_base_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesc_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Can change this for different splits\u001b[39;49;00m\n\u001b[0;32m     84\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# --- Process Fake with shuffling ---\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing Fake frames with shuffling...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 50\u001b[0m, in \u001b[0;36mshuffle_split_and_move\u001b[1;34m(grouped, source_dir, target_dirs, val_size, test_size, desc_prefix, random_seed)\u001b[0m\n\u001b[0;32m     47\u001b[0m     video_ids \u001b[38;5;241m=\u001b[39m video_ids[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Split video groups\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m train_ids, temp_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m val_ids, test_ids \u001b[38;5;241m=\u001b[39m train_test_split(temp_ids, \n\u001b[0;32m     54\u001b[0m                                    test_size\u001b[38;5;241m=\u001b[39m(test_size \u001b[38;5;241m/\u001b[39m (val_size \u001b[38;5;241m+\u001b[39m test_size)),\n\u001b[0;32m     55\u001b[0m                                    random_state\u001b[38;5;241m=\u001b[39mrandom_seed)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmove\u001b[39m(video_ids, dest_dir, desc):\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2778\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2775\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2777\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2778\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2780\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\my_env\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2408\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2405\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2408\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2412\u001b[0m     )\n\u001b[0;32m   2414\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=0, test_size=0.30000000000000004 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "input_base_path = r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\BothDatasets\\FramesExtracted\"\n",
    "output_base_path = r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\BothDatasets\\NewModelTrainingDataset\"\n",
    "\n",
    "real_frames_path = os.path.join(input_base_path, \"RealFrames\")\n",
    "fake_frames_path = os.path.join(input_base_path, \"FakeFrames\")\n",
    "\n",
    "splits = ['train', 'val', 'test']\n",
    "categories = ['Real', 'Fake']\n",
    "\n",
    "# Create folder structure\n",
    "for split in splits:\n",
    "    for category in categories:\n",
    "        os.makedirs(os.path.join(output_base_path, split, category), exist_ok=True)\n",
    "\n",
    "# --- Utility: Extract video ID from any forensic frame filename ---\n",
    "def extract_video_id(filename):\n",
    "    parts = filename.split('_')\n",
    "    if len(parts) >= 3 and parts[0] == 'id' and parts[2].startswith('frame'):\n",
    "        return f\"{parts[0]}_{parts[1]}\"\n",
    "    return filename.split('_frame')[0] if '_frame' in filename else filename.split('.')[0]\n",
    "\n",
    "# --- Group frames by their video ID ---\n",
    "def group_frames_by_video(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith(\".jpg\")]\n",
    "    grouped = defaultdict(list)\n",
    "    for f in files:\n",
    "        video_id = extract_video_id(f)\n",
    "        grouped[video_id].append(f)\n",
    "    return grouped\n",
    "\n",
    "# --- Shuffle and split videos safely ---\n",
    "def shuffle_split_and_move(grouped, source_dir, target_dirs, val_size=0.2, test_size=0.1, desc_prefix=\"\", random_seed=42):\n",
    "    # Get all video IDs and shuffle them\n",
    "    video_ids = list(grouped.keys())\n",
    "    random.shuffle(video_ids)  # Proper shuffling added here\n",
    "    \n",
    "    # Drop one if odd to keep balancing clean\n",
    "    if len(video_ids) % 2 != 0:\n",
    "        video_ids = video_ids[:-1]\n",
    "\n",
    "    # Split video groups\n",
    "    train_ids, temp_ids = train_test_split(video_ids, \n",
    "                                         test_size=(val_size + test_size),\n",
    "                                         random_state=random_seed)\n",
    "    val_ids, test_ids = train_test_split(temp_ids, \n",
    "                                       test_size=(test_size / (val_size + test_size)),\n",
    "                                       random_state=random_seed)\n",
    "\n",
    "    def move(video_ids, dest_dir, desc):\n",
    "        for vid in tqdm(video_ids, desc=f\"{desc_prefix} - {desc}\", unit=\"video\"):\n",
    "            for frame in grouped[vid]:\n",
    "                src_path = os.path.join(source_dir, frame)\n",
    "                dest_path = os.path.join(dest_dir, frame)\n",
    "                if os.path.exists(src_path):\n",
    "                    shutil.move(src_path, dest_path)\n",
    "                else:\n",
    "                    print(f\"Warning: File not found - {src_path}\")\n",
    "\n",
    "    move(train_ids, target_dirs[\"train\"], \"Train\")\n",
    "    move(val_ids, target_dirs[\"val\"], \"Validation\")\n",
    "    move(test_ids, target_dirs[\"test\"], \"Test\")\n",
    "\n",
    "# --- Process Real with shuffling ---\n",
    "print(\"Processing Real frames with shuffling...\")\n",
    "real_groups = group_frames_by_video(real_frames_path)\n",
    "shuffle_split_and_move(\n",
    "    real_groups,\n",
    "    real_frames_path,\n",
    "    {\n",
    "        \"train\": os.path.join(output_base_path, \"train\", \"Real\"),\n",
    "        \"val\": os.path.join(output_base_path, \"val\", \"Real\"),\n",
    "        \"test\": os.path.join(output_base_path, \"test\", \"Real\"),\n",
    "    },\n",
    "    desc_prefix=\"Real\",\n",
    "    random_seed=42  # Can change this for different splits\n",
    ")\n",
    "\n",
    "# --- Process Fake with shuffling ---\n",
    "print(\"Processing Fake frames with shuffling...\")\n",
    "fake_groups = group_frames_by_video(fake_frames_path)\n",
    "shuffle_split_and_move(\n",
    "    fake_groups,\n",
    "    fake_frames_path,\n",
    "    {\n",
    "        \"train\": os.path.join(output_base_path, \"train\", \"Fake\"),\n",
    "        \"val\": os.path.join(output_base_path, \"val\", \"Fake\"),\n",
    "        \"test\": os.path.join(output_base_path, \"test\", \"Fake\"),\n",
    "    },\n",
    "    desc_prefix=\"Fake\",\n",
    "    random_seed=42  # Keep same seed for consistent splits\n",
    ")\n",
    "\n",
    "print(\"\\n✅ All frames split by video ID with proper shuffling and NO data leakage!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80f6e8-281f-4faf-b94c-020602654bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
