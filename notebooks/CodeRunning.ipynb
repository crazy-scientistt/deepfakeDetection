{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image \n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Input paths\n",
    "input_base_path = r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\BothDatasets\\combined_dataset\"\n",
    "real_videos_path = os.path.join(input_base_path, \"real\")\n",
    "fake_videos_path = os.path.join(input_base_path, \"fake\")\n",
    "\n",
    "# Output paths\n",
    "output_base_path = r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\BothDatasets\\FramesExtracted\"\n",
    "real_output_path = os.path.join(output_base_path, \"RealFrames\")\n",
    "fake_output_path = os.path.join(output_base_path, \"FakeFrames\")\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(real_output_path, exist_ok=True)\n",
    "os.makedirs(fake_output_path, exist_ok=True)\n",
    "\n",
    "def extract_frames(video_path, output_folder, video_name, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames < num_frames:\n",
    "        print(f\"Skipping {video_name}: Not enough frames.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "    saved = 0\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i in frame_indices:\n",
    "            frame_filename = f\"{video_name}_frame{saved+1:02d}.jpg\"\n",
    "            frame_path = os.path.join(output_folder, frame_filename)\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            saved += 1\n",
    "    cap.release()\n",
    "\n",
    "# Process real videos\n",
    "print(\"Processing real videos...\")\n",
    "for video_file in os.listdir(real_videos_path):\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(real_videos_path, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        extract_frames(video_path, real_output_path, video_name)\n",
    "\n",
    "# Process fake videos, but only 590 of them\n",
    "print(\"Processing fake videos (limit: 1090 videos)...\")\n",
    "fake_video_count = 0\n",
    "fake_video_limit = 1090\n",
    "\n",
    "for video_file in os.listdir(fake_videos_path):\n",
    "    if fake_video_count >= fake_video_limit:\n",
    "        break\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(fake_videos_path, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        extract_frames(video_path, fake_output_path, video_name)\n",
    "        fake_video_count += 1\n",
    "\n",
    "print(\"Done extracting frames.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✱] Cleared existing files in 'frames'\n",
      "[✓] Saved frames/face_80_0.jpg\n",
      "[✓] Saved frames/face_80_1.jpg\n",
      "[✓] Saved frames/face_100_0.jpg\n",
      "[✓] Saved frames/face_100_1.jpg\n",
      "[✓] Saved frames/face_120_0.jpg\n",
      "[✓] Saved frames/face_140_0.jpg\n",
      "[✓] Saved frames/face_140_1.jpg\n",
      "[✓] Saved frames/face_160_0.jpg\n",
      "[✓] Saved frames/face_160_1.jpg\n",
      "[✓] Saved frames/face_180_0.jpg\n",
      "[✓] Saved frames/face_180_1.jpg\n",
      "[✓] Saved frames/face_200_0.jpg\n",
      "[✓] Saved frames/face_200_1.jpg\n",
      "[✓] Saved frames/face_200_2.jpg\n",
      "[✓] Saved frames/face_220_0.jpg\n",
      "[✓] Saved frames/face_240_0.jpg\n",
      "[✓] Saved frames/face_240_1.jpg\n",
      "[✓] Saved frames/face_260_0.jpg\n",
      "[✓] Saved frames/face_300_0.jpg\n",
      "[✓] Saved frames/face_300_1.jpg\n",
      "[✓] Saved frames/face_300_2.jpg\n",
      "[✓] Saved frames/face_320_0.jpg\n",
      "[✓] Saved frames/face_320_1.jpg\n",
      "[✓] Saved frames/face_320_2.jpg\n",
      "[✓] Saved frames/face_340_0.jpg\n",
      "[✓] Saved frames/face_360_0.jpg\n",
      "[✓] Saved frames/face_360_1.jpg\n",
      "[✓] Saved frames/face_380_0.jpg\n",
      "[✓] Saved frames/face_400_0.jpg\n",
      "[✓] Saved frames/face_420_0.jpg\n",
      "[✓] Saved frames/face_440_0.jpg\n",
      "[✓] Saved frames/face_460_0.jpg\n",
      "[✓] Saved frames/face_480_0.jpg\n",
      "[✓] Saved frames/face_500_0.jpg\n",
      "[✓] Saved frames/face_520_0.jpg\n",
      "[✓] Saved frames/face_520_1.jpg\n",
      "[✓] Saved frames/face_540_0.jpg\n",
      "[✓] Saved frames/face_540_1.jpg\n",
      "[✓] Saved frames/face_560_0.jpg\n",
      "[✓] Saved frames/face_560_1.jpg\n",
      "[✓] Saved frames/face_580_0.jpg\n",
      "[✓] Saved frames/face_600_0.jpg\n",
      "[✓] Saved frames/face_620_2.jpg\n",
      "[✓] Saved frames/face_640_1.jpg\n",
      "[✓] Saved frames/face_660_1.jpg\n",
      "[✓] Saved frames/face_680_1.jpg\n",
      "[✓] Saved frames/face_700_2.jpg\n",
      "[✓] Saved frames/face_720_2.jpg\n",
      "[✓] Saved frames/face_740_2.jpg\n",
      "[✓] Saved frames/face_760_1.jpg\n",
      "[✓] Saved frames/face_780_1.jpg\n",
      "[✓] Saved frames/face_800_1.jpg\n",
      "[✓] Saved frames/face_820_2.jpg\n",
      "[✓] Saved frames/face_840_2.jpg\n",
      "[✓] Saved frames/face_860_1.jpg\n",
      "[✓] Saved frames/face_880_0.jpg\n",
      "[✓] Saved frames/face_900_0.jpg\n",
      "[✓] Saved frames/face_920_0.jpg\n",
      "[✓] Saved frames/face_960_2.jpg\n",
      "[✓] Saved frames/face_980_2.jpg\n",
      "[✓] Saved frames/face_1000_2.jpg\n",
      "[✓] Saved frames/face_1020_1.jpg\n",
      "[✓] Saved frames/face_1040_0.jpg\n",
      "[✓] Saved frames/face_1060_0.jpg\n",
      "[✓] Saved frames/face_1060_1.jpg\n",
      "[✓] Saved frames/face_1060_2.jpg\n",
      "[✓] Saved frames/face_1060_3.jpg\n",
      "[✓] Saved frames/face_1060_4.jpg\n",
      "[✓] Saved frames/face_1080_0.jpg\n",
      "[✓] Saved frames/face_1080_1.jpg\n",
      "[✓] Saved frames/face_1080_2.jpg\n",
      "[✓] Saved frames/face_1080_4.jpg\n",
      "[✓] Saved frames/face_1100_0.jpg\n",
      "[✓] Saved frames/face_1100_1.jpg\n",
      "[✓] Saved frames/face_1100_2.jpg\n",
      "[✓] Saved frames/face_1120_0.jpg\n",
      "[✓] Saved frames/face_1120_1.jpg\n",
      "[✓] Saved frames/face_1140_0.jpg\n",
      "[✓] Saved frames/face_1140_1.jpg\n",
      "[✓] Saved frames/face_1160_0.jpg\n",
      "[✓] Saved frames/face_1160_1.jpg\n",
      "[✓] Saved frames/face_1160_2.jpg\n",
      "[✓] Saved frames/face_1180_0.jpg\n",
      "[✓] Saved frames/face_1200_0.jpg\n",
      "[✓] Saved frames/face_1220_0.jpg\n",
      "[✓] Saved frames/face_1240_0.jpg\n",
      "[✓] Saved frames/face_1260_0.jpg\n",
      "[✓] Saved frames/face_1280_0.jpg\n",
      "[✓] Saved frames/face_1300_0.jpg\n",
      "[✓] Saved frames/face_1320_0.jpg\n",
      "[✓] Saved frames/face_1340_0.jpg\n",
      "[✓] Saved frames/face_1360_0.jpg\n",
      "[✓] Saved frames/face_1380_0.jpg\n",
      "[✓] Saved frames/face_1400_0.jpg\n",
      "[✓] Saved frames/face_1420_1.jpg\n",
      "[✓] Saved frames/face_1440_0.jpg\n",
      "[✓] Saved frames/face_1460_1.jpg\n",
      "[✓] Saved frames/face_1480_0.jpg\n",
      "[✓] Saved frames/face_1500_0.jpg\n",
      "[✓] Saved frames/face_1520_0.jpg\n",
      "[✓] Saved frames/face_1540_0.jpg\n",
      "[✓] Saved frames/face_1560_0.jpg\n",
      "[✓] Saved frames/face_1580_0.jpg\n",
      "[✓] Saved frames/face_1600_0.jpg\n",
      "[✓] Saved frames/face_1600_2.jpg\n",
      "[✓] Saved frames/face_1620_0.jpg\n",
      "[✓] Saved frames/face_1640_1.jpg\n",
      "[✓] Saved frames/face_1660_1.jpg\n",
      "[✓] Saved frames/face_1680_0.jpg\n",
      "[✓] Saved frames/face_1700_0.jpg\n",
      "[✓] Saved frames/face_1720_0.jpg\n",
      "[✓] Saved frames/face_1740_0.jpg\n",
      "[✓] Saved frames/face_1760_0.jpg\n",
      "[✓] Saved frames/face_1780_0.jpg\n",
      "[✓] Saved frames/face_1800_0.jpg\n",
      "[✓] Saved frames/face_1820_0.jpg\n",
      "[✓] Saved frames/face_1840_0.jpg\n",
      "[✓] Saved frames/face_1860_0.jpg\n",
      "[✓] Saved frames/face_1880_0.jpg\n",
      "[✓] Saved frames/face_1900_0.jpg\n",
      "[✓] Saved frames/face_1920_0.jpg\n",
      "[✓] Saved frames/face_1940_0.jpg\n",
      "[✓] Saved frames/face_1960_0.jpg\n",
      "[✓] Saved frames/face_1980_0.jpg\n",
      "[✓] Saved frames/face_1980_1.jpg\n",
      "[✓] Saved frames/face_2000_0.jpg\n",
      "[✓] Saved frames/face_2020_0.jpg\n",
      "[✓] Saved frames/face_2040_0.jpg\n",
      "[✓] Saved frames/face_2060_0.jpg\n",
      "[✓] Saved frames/face_2080_0.jpg\n",
      "[✓] Saved frames/face_2100_0.jpg\n",
      "[✓] Saved frames/face_2120_0.jpg\n",
      "[✓] Saved frames/face_2140_0.jpg\n",
      "[✓] Saved frames/face_2160_0.jpg\n",
      "[✓] Saved frames/face_2180_0.jpg\n",
      "[✓] Saved frames/face_2200_0.jpg\n",
      "[✓] Saved frames/face_2220_0.jpg\n",
      "[✓] Saved frames/face_2240_0.jpg\n",
      "[✓] Saved frames/face_2260_0.jpg\n",
      "[✓] Saved frames/face_2280_0.jpg\n",
      "[✓] Saved frames/face_2300_0.jpg\n",
      "[✓] Saved frames/face_2320_0.jpg\n",
      "[✓] Saved frames/face_2320_1.jpg\n",
      "[✓] Saved frames/face_2340_0.jpg\n",
      "[✓] Saved frames/face_2360_0.jpg\n",
      "[✓] Saved frames/face_2360_1.jpg\n",
      "[✓] Saved frames/face_2360_2.jpg\n",
      "[✓] Saved frames/face_2380_0.jpg\n",
      "[✓] Saved frames/face_2380_1.jpg\n",
      "[✓] Saved frames/face_2380_2.jpg\n",
      "[✓] Saved frames/face_2380_3.jpg\n",
      "[✓] Saved frames/face_2400_0.jpg\n",
      "[✓] Saved frames/face_2400_1.jpg\n",
      "[✓] Saved frames/face_2400_2.jpg\n",
      "[✓] Saved frames/face_2420_0.jpg\n",
      "[✓] Saved frames/face_2420_1.jpg\n",
      "[✓] Saved frames/face_2420_2.jpg\n",
      "[✓] Saved frames/face_2440_0.jpg\n",
      "[✓] Saved frames/face_2440_1.jpg\n",
      "[✓] Saved frames/face_2440_2.jpg\n",
      "[✓] Saved frames/face_2460_0.jpg\n",
      "[✓] Saved frames/face_2480_0.jpg\n",
      "[✓] Saved frames/face_2500_0.jpg\n",
      "[✓] Saved frames/face_2520_0.jpg\n",
      "[✓] Saved frames/face_2540_0.jpg\n",
      "[✓] Saved frames/face_2560_0.jpg\n",
      "[✓] Saved frames/face_2580_0.jpg\n",
      "[✓] Saved frames/face_2600_0.jpg\n",
      "[✓] Saved frames/face_2620_0.jpg\n",
      "[✓] Saved frames/face_2620_1.jpg\n",
      "[✓] Saved frames/face_2660_0.jpg\n",
      "[✓] Saved frames/face_2660_1.jpg\n",
      "[✓] Saved frames/face_2660_2.jpg\n",
      "[✓] Saved frames/face_2680_0.jpg\n",
      "[✓] Saved frames/face_2700_0.jpg\n",
      "[✓] Saved frames/face_2720_0.jpg\n",
      "[✓] Saved frames/face_2740_0.jpg\n",
      "[✓] Saved frames/face_2760_0.jpg\n",
      "[✓] Saved frames/face_2780_0.jpg\n",
      "[✓] Saved frames/face_2800_0.jpg\n",
      "[✓] Saved frames/face_2820_0.jpg\n",
      "[✓] Saved frames/face_2840_0.jpg\n",
      "[✓] Saved frames/face_2860_0.jpg\n",
      "[✓] Saved frames/face_2880_0.jpg\n",
      "[✓] Saved frames/face_2900_0.jpg\n",
      "[✓] Saved frames/face_2920_0.jpg\n",
      "[✓] Saved frames/face_2940_0.jpg\n",
      "[✓] Saved frames/face_2960_0.jpg\n",
      "[✓] Saved frames/face_2960_1.jpg\n",
      "[✓] Saved frames/face_2960_2.jpg\n",
      "[✓] Saved frames/face_2960_3.jpg\n",
      "[✓] Saved frames/face_2980_0.jpg\n",
      "[✓] Saved frames/face_2980_1.jpg\n",
      "[✓] Saved frames/face_3000_0.jpg\n",
      "[✓] Saved frames/face_3000_1.jpg\n",
      "[✓] Saved frames/face_3020_0.jpg\n",
      "[✓] Saved frames/face_3020_1.jpg\n",
      "[✓] Saved frames/face_3040_0.jpg\n",
      "[✓] Saved frames/face_3060_0.jpg\n",
      "[✓] Saved frames/face_3060_1.jpg\n",
      "[✓] Saved frames/face_3060_2.jpg\n",
      "[✓] Saved frames/face_3080_0.jpg\n",
      "[✓] Saved frames/face_3080_1.jpg\n",
      "[✓] Saved frames/face_3100_0.jpg\n",
      "[✓] Saved frames/face_3100_1.jpg\n",
      "[✓] Saved frames/face_3120_0.jpg\n",
      "[✓] Saved frames/face_3140_0.jpg\n",
      "[✓] Saved frames/face_3160_0.jpg\n",
      "[✓] Saved frames/face_3180_0.jpg\n",
      "[✓] Saved frames/face_3200_0.jpg\n",
      "[✓] Saved frames/face_3220_0.jpg\n",
      "[✓] Saved frames/face_3240_0.jpg\n",
      "[✓] Saved frames/face_3260_0.jpg\n",
      "[✓] Saved frames/face_3280_0.jpg\n",
      "[✓] Saved frames/face_3300_0.jpg\n",
      "[✓] Saved frames/face_3320_0.jpg\n",
      "[✓] Saved frames/face_3340_0.jpg\n",
      "[✓] Saved frames/face_3360_0.jpg\n",
      "[✓] Saved frames/face_3380_0.jpg\n",
      "[✓] Saved frames/face_3400_0.jpg\n",
      "[✓] Saved frames/face_3420_0.jpg\n",
      "[✓] Saved frames/face_3440_0.jpg\n",
      "[✓] Saved frames/face_3460_0.jpg\n",
      "[✓] Saved frames/face_3480_0.jpg\n",
      "[✓] Saved frames/face_3500_0.jpg\n",
      "[✓] Saved frames/face_3520_0.jpg\n",
      "[✓] Saved frames/face_3540_0.jpg\n",
      "[✓] Saved frames/face_3560_0.jpg\n",
      "[✓] Saved frames/face_3580_0.jpg\n",
      "[✓] Saved frames/face_3600_0.jpg\n",
      "[✓] Saved frames/face_3620_0.jpg\n",
      "[✓] Saved frames/face_3640_0.jpg\n",
      "[✓] Saved frames/face_3660_0.jpg\n",
      "[✓] Saved frames/face_3680_0.jpg\n",
      "[✓] Saved frames/face_3700_0.jpg\n",
      "[✓] Saved frames/face_3720_0.jpg\n",
      "[✓] Saved frames/face_3740_0.jpg\n",
      "[✓] Saved frames/face_3760_0.jpg\n",
      "[✓] Saved frames/face_3780_0.jpg\n",
      "[✓] Saved frames/face_3800_0.jpg\n",
      "[✓] Saved frames/face_3820_0.jpg\n",
      "[✓] Saved frames/face_3840_0.jpg\n",
      "[✓] Saved frames/face_3860_0.jpg\n",
      "[✓] Saved frames/face_3880_0.jpg\n",
      "[✓] Saved frames/face_3900_0.jpg\n",
      "[✓] Saved frames/face_3920_0.jpg\n",
      "[✓] Saved frames/face_3940_0.jpg\n",
      "[✓] Saved frames/face_3960_0.jpg\n",
      "[✓] Saved frames/face_3980_0.jpg\n",
      "[✓] Saved frames/face_4000_0.jpg\n",
      "[✓] Saved frames/face_4020_0.jpg\n",
      "[✓] Saved frames/face_4040_0.jpg\n",
      "[✓] Saved frames/face_4060_0.jpg\n",
      "[✓] Saved frames/face_4080_0.jpg\n",
      "[✓] Saved frames/face_4100_0.jpg\n",
      "[✓] Saved frames/face_4120_0.jpg\n",
      "[✓] Saved frames/face_4140_0.jpg\n",
      "[✓] Saved frames/face_4160_0.jpg\n",
      "[✓] Saved frames/face_4180_0.jpg\n",
      "[✓] Saved frames/face_4200_0.jpg\n",
      "[✓] Saved frames/face_4220_0.jpg\n",
      "[✓] Saved frames/face_4240_0.jpg\n",
      "[✓] Saved frames/face_4260_0.jpg\n",
      "[✓] Saved frames/face_4280_0.jpg\n",
      "[✓] Saved frames/face_4300_0.jpg\n",
      "[✓] Saved frames/face_4320_0.jpg\n",
      "[✓] Saved frames/face_4340_0.jpg\n",
      "[✓] Saved frames/face_4360_0.jpg\n",
      "[✓] Saved frames/face_4380_0.jpg\n",
      "[✓] Saved frames/face_4400_0.jpg\n",
      "[✓] Saved frames/face_4420_0.jpg\n",
      "[✓] Saved frames/face_4440_0.jpg\n",
      "[✓] Saved frames/face_4460_0.jpg\n",
      "[✓] Saved frames/face_4480_0.jpg\n",
      "[✓] Saved frames/face_4500_0.jpg\n",
      "[✓] Saved frames/face_4520_0.jpg\n",
      "[✓] Saved frames/face_4540_0.jpg\n",
      "[✓] Saved frames/face_4560_0.jpg\n",
      "[✓] Saved frames/face_4580_0.jpg\n",
      "[✓] Saved frames/face_4600_0.jpg\n",
      "[✓] Saved frames/face_4620_0.jpg\n",
      "[✓] Saved frames/face_4640_0.jpg\n",
      "[✓] Saved frames/face_4660_0.jpg\n",
      "[✓] Saved frames/face_4680_0.jpg\n",
      "[✓] Saved frames/face_4700_0.jpg\n",
      "[✓] Saved frames/face_4720_0.jpg\n",
      "[✓] Saved frames/face_4740_0.jpg\n",
      "[✓] Saved frames/face_4760_0.jpg\n",
      "[✓] Saved frames/face_4780_0.jpg\n",
      "[✓] Saved frames/face_4800_0.jpg\n",
      "[✓] Saved frames/face_4820_0.jpg\n",
      "[✓] Saved frames/face_4840_0.jpg\n",
      "[✓] Saved frames/face_4860_0.jpg\n",
      "[✓] Saved frames/face_4880_0.jpg\n",
      "[✓] Saved frames/face_4900_0.jpg\n",
      "[✓] Saved frames/face_4920_0.jpg\n",
      "[✓] Saved frames/face_4940_0.jpg\n",
      "[✓] Saved frames/face_4960_0.jpg\n",
      "[✓] Saved frames/face_4980_0.jpg\n",
      "[✓] Saved frames/face_5000_0.jpg\n",
      "[✓] Saved frames/face_5020_0.jpg\n",
      "[✓] Saved frames/face_5040_0.jpg\n",
      "[✓] Saved frames/face_5060_0.jpg\n",
      "[✓] Saved frames/face_5060_1.jpg\n",
      "[✓] Saved frames/face_5080_0.jpg\n",
      "[✓] Saved frames/face_5080_1.jpg\n",
      "[✓] Saved frames/face_5100_0.jpg\n",
      "[✓] Saved frames/face_5120_0.jpg\n",
      "[✓] Saved frames/face_5140_0.jpg\n",
      "[✓] Saved frames/face_5160_0.jpg\n",
      "[✓] Saved frames/face_5180_0.jpg\n",
      "[✓] Saved frames/face_5200_0.jpg\n",
      "[✓] Saved frames/face_5220_0.jpg\n",
      "[✓] Saved frames/face_5240_0.jpg\n",
      "[✓] Saved frames/face_5260_1.jpg\n",
      "[✓] Saved frames/face_5300_0.jpg\n",
      "[✓] Saved frames/face_5300_1.jpg\n",
      "[✓] Saved frames/face_5300_2.jpg\n",
      "[✓] Saved frames/face_5300_3.jpg\n",
      "[✓] Saved frames/face_5320_0.jpg\n",
      "[✓] Saved frames/face_5340_0.jpg\n",
      "[✓] Saved frames/face_5360_0.jpg\n",
      "[✓] Saved frames/face_5380_0.jpg\n",
      "[✓] Saved frames/face_5400_0.jpg\n",
      "[✓] Saved frames/face_5420_0.jpg\n",
      "[✓] Saved frames/face_5440_0.jpg\n",
      "[✓] Saved frames/face_5460_0.jpg\n",
      "[✓] Saved frames/face_5480_0.jpg\n",
      "[✓] Saved frames/face_5500_0.jpg\n",
      "[✓] Saved frames/face_5520_0.jpg\n",
      "[✓] Saved frames/face_5540_0.jpg\n",
      "[✓] Saved frames/face_5560_0.jpg\n",
      "[✓] Saved frames/face_5580_0.jpg\n",
      "[✓] Saved frames/face_5600_0.jpg\n",
      "[✓] Saved frames/face_5620_0.jpg\n",
      "[✓] Saved frames/face_5620_1.jpg\n",
      "[✓] Saved frames/face_5640_0.jpg\n",
      "[✓] Saved frames/face_5640_1.jpg\n",
      "[✓] Saved frames/face_5640_2.jpg\n",
      "[✓] Saved frames/face_5660_0.jpg\n",
      "[✓] Saved frames/face_5660_1.jpg\n",
      "[✓] Saved frames/face_5680_0.jpg\n",
      "[✓] Saved frames/face_5680_1.jpg\n",
      "[✓] Saved frames/face_5700_0.jpg\n",
      "[✓] Saved frames/face_5700_1.jpg\n",
      "\n",
      "Done: 345 face crops saved.\n",
      "No faces detected, removing: face_100_0.jpg\n",
      "No faces detected, removing: face_100_1.jpg\n",
      "No faces detected, removing: face_1020_1.jpg\n",
      "No faces detected, removing: face_1060_1.jpg\n",
      "No faces detected, removing: face_1060_3.jpg\n",
      "No faces detected, removing: face_1080_1.jpg\n",
      "No faces detected, removing: face_1080_2.jpg\n",
      "No faces detected, removing: face_1120_0.jpg\n",
      "No faces detected, removing: face_1140_0.jpg\n",
      "No faces detected, removing: face_1140_1.jpg\n",
      "No faces detected, removing: face_1160_1.jpg\n",
      "No faces detected, removing: face_1160_2.jpg\n",
      "No faces detected, removing: face_1540_0.jpg\n",
      "No faces detected, removing: face_1600_0.jpg\n",
      "No faces detected, removing: face_180_1.jpg\n",
      "Duplicate found and removing: face_1880_0.jpg\n",
      "Duplicate found and removing: face_1940_0.jpg\n",
      "No faces detected, removing: face_1980_0.jpg\n",
      "No faces detected, removing: face_200_2.jpg\n",
      "No faces detected, removing: face_2040_0.jpg\n",
      "Duplicate found and removing: face_2160_0.jpg\n",
      "No faces detected, removing: face_220_0.jpg\n",
      "No faces detected, removing: face_2320_0.jpg\n",
      "No faces detected, removing: face_2360_0.jpg\n",
      "No faces detected, removing: face_2360_1.jpg\n",
      "No faces detected, removing: face_2360_2.jpg\n",
      "No faces detected, removing: face_2380_0.jpg\n",
      "No faces detected, removing: face_2380_1.jpg\n",
      "No faces detected, removing: face_2380_2.jpg\n",
      "No faces detected, removing: face_2400_1.jpg\n",
      "No faces detected, removing: face_240_0.jpg\n",
      "No faces detected, removing: face_2440_1.jpg\n",
      "No faces detected, removing: face_2440_2.jpg\n",
      "No faces detected, removing: face_2600_0.jpg\n",
      "No faces detected, removing: face_2620_1.jpg\n",
      "No faces detected, removing: face_2660_0.jpg\n",
      "No faces detected, removing: face_2960_1.jpg\n",
      "No faces detected, removing: face_2960_2.jpg\n",
      "Duplicate found and removing: face_2980_0.jpg\n",
      "Duplicate found and removing: face_3000_0.jpg\n",
      "No faces detected, removing: face_300_1.jpg\n",
      "Duplicate found and removing: face_3020_0.jpg\n",
      "Duplicate found and removing: face_3040_0.jpg\n",
      "No faces detected, removing: face_3060_1.jpg\n",
      "No faces detected, removing: face_3060_2.jpg\n",
      "Duplicate found and removing: face_3080_0.jpg\n",
      "Duplicate found and removing: face_3100_0.jpg\n",
      "Duplicate found and removing: face_3160_0.jpg\n",
      "No faces detected, removing: face_320_1.jpg\n",
      "Duplicate found and removing: face_3240_0.jpg\n",
      "Duplicate found and removing: face_3260_0.jpg\n",
      "Duplicate found and removing: face_3320_0.jpg\n",
      "Duplicate found and removing: face_3340_0.jpg\n",
      "Duplicate found and removing: face_3380_0.jpg\n",
      "Duplicate found and removing: face_3540_0.jpg\n",
      "Duplicate found and removing: face_3580_0.jpg\n",
      "Duplicate found and removing: face_3600_0.jpg\n",
      "No faces detected, removing: face_360_1.jpg\n",
      "Duplicate found and removing: face_3640_0.jpg\n",
      "Duplicate found and removing: face_3720_0.jpg\n",
      "Duplicate found and removing: face_3740_0.jpg\n",
      "Duplicate found and removing: face_3780_0.jpg\n",
      "No faces detected, removing: face_380_0.jpg\n",
      "Duplicate found and removing: face_3820_0.jpg\n",
      "Duplicate found and removing: face_3840_0.jpg\n",
      "Duplicate found and removing: face_3860_0.jpg\n",
      "Duplicate found and removing: face_3940_0.jpg\n",
      "Duplicate found and removing: face_3960_0.jpg\n",
      "Duplicate found and removing: face_4020_0.jpg\n",
      "Duplicate found and removing: face_4040_0.jpg\n",
      "Duplicate found and removing: face_4060_0.jpg\n",
      "Duplicate found and removing: face_4100_0.jpg\n",
      "Duplicate found and removing: face_4120_0.jpg\n",
      "Duplicate found and removing: face_4140_0.jpg\n",
      "Duplicate found and removing: face_4160_0.jpg\n",
      "Duplicate found and removing: face_4220_0.jpg\n",
      "Duplicate found and removing: face_4240_0.jpg\n",
      "Duplicate found and removing: face_4300_0.jpg\n",
      "Duplicate found and removing: face_4320_0.jpg\n",
      "Duplicate found and removing: face_4340_0.jpg\n",
      "Duplicate found and removing: face_4400_0.jpg\n",
      "Duplicate found and removing: face_4440_0.jpg\n",
      "Duplicate found and removing: face_4480_0.jpg\n",
      "Duplicate found and removing: face_4500_0.jpg\n",
      "Duplicate found and removing: face_4520_0.jpg\n",
      "Duplicate found and removing: face_4560_0.jpg\n",
      "Duplicate found and removing: face_4580_0.jpg\n",
      "Duplicate found and removing: face_4600_0.jpg\n",
      "Duplicate found and removing: face_4620_0.jpg\n",
      "Duplicate found and removing: face_4760_0.jpg\n",
      "No faces detected, removing: face_480_0.jpg\n",
      "Duplicate found and removing: face_4820_0.jpg\n",
      "Duplicate found and removing: face_4860_0.jpg\n",
      "Duplicate found and removing: face_5020_0.jpg\n",
      "No faces detected, removing: face_5060_0.jpg\n",
      "No faces detected, removing: face_5080_0.jpg\n",
      "Duplicate found and removing: face_5120_0.jpg\n",
      "No faces detected, removing: face_520_0.jpg\n",
      "Duplicate found and removing: face_5240_0.jpg\n",
      "No faces detected, removing: face_5300_0.jpg\n",
      "No faces detected, removing: face_5300_1.jpg\n",
      "Duplicate found and removing: face_5380_0.jpg\n",
      "No faces detected, removing: face_540_0.jpg\n",
      "Duplicate found and removing: face_5580_0.jpg\n",
      "Duplicate found and removing: face_5600_0.jpg\n",
      "No faces detected, removing: face_560_0.jpg\n",
      "No faces detected, removing: face_5620_1.jpg\n",
      "Duplicate found and removing: face_5640_0.jpg\n",
      "No faces detected, removing: face_5640_2.jpg\n",
      "No faces detected, removing: face_5660_0.jpg\n",
      "No faces detected, removing: face_5680_0.jpg\n",
      "No faces detected, removing: face_5700_0.jpg\n",
      "No faces detected, removing: face_5700_1.jpg\n",
      "Duplicate found and removing: face_600_0.jpg\n",
      "No faces detected, removing: face_80_1.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import cv2\n",
    "\n",
    "# Path to the folder containing frames\n",
    "frames_directory = r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\notebooks\\frames\"\n",
    "\n",
    "# Load Haar cascade face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def FrameCapture(video_path, output_dir=\"frames\", frame_skip=20, min_face_size=60):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_faces = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=6,\n",
    "                minSize=(min_face_size, min_face_size)\n",
    "            )\n",
    "\n",
    "            for i, (x, y, w, h) in enumerate(faces):\n",
    "                aspect_ratio = w / float(h)\n",
    "                if aspect_ratio < 0.75 or aspect_ratio > 1.33:\n",
    "                    continue\n",
    "\n",
    "                face = frame[y:y+h, x:x+w]\n",
    "                brightness = face.mean()\n",
    "                if brightness < 40:\n",
    "                    continue\n",
    "\n",
    "                filename = f\"{output_dir}/face_{frame_count}_{i}.jpg\"\n",
    "                cv2.imwrite(filename, face)\n",
    "\n",
    "                print(f\"[✓] Saved {filename}\")\n",
    "                saved_faces += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"\\nDone: {saved_faces} face crops saved.\")\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.gif'))\n",
    "\n",
    "def process_file(path, output_dir=\"frames\", min_face_size=60):\n",
    "    # Clear existing frames\n",
    "    if os.path.exists(output_dir):\n",
    "        for f in os.listdir(output_dir):\n",
    "            file_path = os.path.join(output_dir, f)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        print(f\"[✱] Cleared existing files in '{output_dir}'\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if is_image_file(path):\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(\"Error: Cannot read image.\")\n",
    "            return\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=6,\n",
    "            minSize=(min_face_size, min_face_size)\n",
    "        )\n",
    "\n",
    "        total_saved = 0\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            aspect_ratio = w / float(h)\n",
    "            if aspect_ratio < 0.75 or aspect_ratio > 1.33:\n",
    "                continue\n",
    "\n",
    "            face = img[y:y+h, x:x+w]\n",
    "            brightness = face.mean()\n",
    "            if brightness < 40:\n",
    "                continue\n",
    "\n",
    "            # Save 30 copies of the face\n",
    "            for j in range(30):\n",
    "                filename = f\"{output_dir}/image_face_{i}_copy_{j}.jpg\"\n",
    "                cv2.imwrite(filename, face)\n",
    "\n",
    "                print(f\"[✓] Saved {filename}\")\n",
    "                total_saved += 1\n",
    "\n",
    "        print(f\"[→] Detected {len(faces)} valid face(s)\")\n",
    "        print(f\"[→] Saved {total_saved} face crops (30 per face)\")\n",
    "    else:\n",
    "        FrameCapture(path)\n",
    "\n",
    "\n",
    "def remove_non_face_and_duplicate_frames(directory):\n",
    "    # Set to store unique hashes of images\n",
    "    seen_hashes = set()\n",
    "\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # Iterate over all files\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "\n",
    "        # Only consider image files (you can extend this list if needed)\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            try:\n",
    "                # Open image and compute hash\n",
    "                image = Image.open(file_path)\n",
    "                image_hash = imagehash.average_hash(image)\n",
    "\n",
    "                # Detect faces in the image\n",
    "                img_cv = cv2.imread(file_path)\n",
    "                gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "                # If no faces are detected, remove the image\n",
    "                if len(faces) == 0:\n",
    "                    print(f\"No faces detected, removing: {file}\")\n",
    "                    os.remove(file_path)\n",
    "                else:\n",
    "                    # Check if the image hash is already in the set (duplicate)\n",
    "                    if image_hash in seen_hashes:\n",
    "                        print(f\"Duplicate found and removing: {file}\")\n",
    "                        os.remove(file_path)\n",
    "                    else:\n",
    "                        # Otherwise, add the hash to the set (unique image with face)\n",
    "                        seen_hashes.add(image_hash)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "process_file(r\"C:\\Users\\creat\\Desktop\\Testing videos\\interview.mp4\")\n",
    "remove_non_face_and_duplicate_frames(frames_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Load your saved Xception-based model\n",
    "loaded_model = load_model(r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\models\\best models\\fine_tuned_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-frame predictions (Fake class confidence):\n",
      "  Frame 1: 0.5499\n",
      "  Frame 2: 0.5206\n",
      "  Frame 3: 0.9902\n",
      "  Frame 4: 0.9489\n",
      "  Frame 5: 0.3430\n",
      "  Frame 6: 0.9839\n",
      "  Frame 7: 0.3598\n",
      "  Frame 8: 0.9796\n",
      "  Frame 9: 0.8406\n",
      "  Frame 10: 0.4805\n",
      "  Frame 11: 0.4464\n",
      "  Frame 12: 0.9629\n",
      "  Frame 13: 0.8704\n",
      "  Frame 14: 0.8946\n",
      "  Frame 15: 0.8319\n",
      "  Frame 16: 0.8445\n",
      "  Frame 17: 0.8209\n",
      "  Frame 18: 0.8679\n",
      "  Frame 19: 0.9470\n",
      "  Frame 20: 0.9821\n",
      "  Frame 21: 0.9425\n",
      "  Frame 22: 0.9329\n",
      "  Frame 23: 0.9493\n",
      "  Frame 24: 0.8749\n",
      "  Frame 25: 0.8218\n",
      "  Frame 26: 0.9806\n",
      "  Frame 27: 0.7248\n",
      "  Frame 28: 0.9019\n",
      "  Frame 29: 0.9373\n",
      "  Frame 30: 0.8494\n",
      "  Frame 31: 0.8664\n",
      "  Frame 32: 0.8919\n",
      "  Frame 33: 0.8977\n",
      "  Frame 34: 0.8587\n",
      "  Frame 35: 0.9077\n",
      "  Frame 36: 0.9072\n",
      "  Frame 37: 0.8723\n",
      "  Frame 38: 0.9799\n",
      "  Frame 39: 0.8419\n",
      "  Frame 40: 0.9052\n",
      "  Frame 41: 0.7904\n",
      "  Frame 42: 0.9866\n",
      "  Frame 43: 0.8477\n",
      "  Frame 44: 0.9188\n",
      "  Frame 45: 0.8002\n",
      "  Frame 46: 0.8375\n",
      "  Frame 47: 0.8663\n",
      "  Frame 48: 0.8236\n",
      "  Frame 49: 0.9193\n",
      "  Frame 50: 0.9242\n",
      "  Frame 51: 0.9302\n",
      "  Frame 52: 0.8963\n",
      "  Frame 53: 0.9662\n",
      "  Frame 54: 0.9612\n",
      "  Frame 55: 0.8407\n",
      "  Frame 56: 0.2477\n",
      "  Frame 57: 0.5916\n",
      "  Frame 58: 0.8238\n",
      "  Frame 59: 0.9690\n",
      "  Frame 60: 0.9215\n",
      "  Frame 61: 0.8717\n",
      "  Frame 62: 0.8732\n",
      "  Frame 63: 0.7719\n",
      "  Frame 64: 0.7745\n",
      "  Frame 65: 0.7361\n",
      "  Frame 66: 0.8382\n",
      "  Frame 67: 0.6913\n",
      "  Frame 68: 0.9012\n",
      "  Frame 69: 0.8902\n",
      "  Frame 70: 0.7634\n",
      "  Frame 71: 0.8329\n",
      "  Frame 72: 0.9264\n",
      "  Frame 73: 0.8506\n",
      "  Frame 74: 0.7653\n",
      "  Frame 75: 0.9551\n",
      "  Frame 76: 0.9982\n",
      "  Frame 77: 0.9941\n",
      "  Frame 78: 0.9756\n",
      "  Frame 79: 0.5560\n",
      "  Frame 80: 0.9922\n",
      "  Frame 81: 0.9444\n",
      "  Frame 82: 0.6684\n",
      "  Frame 83: 0.9551\n",
      "  Frame 84: 0.9794\n",
      "  Frame 85: 0.8850\n",
      "  Frame 86: 0.8328\n",
      "  Frame 87: 0.8961\n",
      "  Frame 88: 0.8752\n",
      "  Frame 89: 0.9014\n",
      "  Frame 90: 0.9405\n",
      "  Frame 91: 0.2173\n",
      "  Frame 92: 0.9262\n",
      "  Frame 93: 0.9859\n",
      "  Frame 94: 0.9488\n",
      "  Frame 95: 0.9655\n",
      "  Frame 96: 0.9689\n",
      "  Frame 97: 0.7989\n",
      "  Frame 98: 0.9400\n",
      "  Frame 99: 0.9909\n",
      "  Frame 100: 0.9733\n",
      "  Frame 101: 0.9340\n",
      "  Frame 102: 0.7869\n",
      "  Frame 103: 0.8397\n",
      "  Frame 104: 0.6960\n",
      "  Frame 105: 0.7307\n",
      "  Frame 106: 0.7669\n",
      "  Frame 107: 0.8507\n",
      "  Frame 108: 0.8001\n",
      "  Frame 109: 0.9382\n",
      "  Frame 110: 0.6708\n",
      "  Frame 111: 0.8171\n",
      "  Frame 112: 0.8268\n",
      "  Frame 113: 0.9441\n",
      "  Frame 114: 0.7931\n",
      "  Frame 115: 0.6753\n",
      "  Frame 116: 0.9350\n",
      "  Frame 117: 0.9887\n",
      "  Frame 118: 0.9588\n",
      "  Frame 119: 0.8991\n",
      "  Frame 120: 0.8940\n",
      "  Frame 121: 0.9353\n",
      "  Frame 122: 0.8872\n",
      "  Frame 123: 0.9864\n",
      "  Frame 124: 0.8824\n",
      "  Frame 125: 0.9452\n",
      "  Frame 126: 0.9517\n",
      "  Frame 127: 0.9438\n",
      "  Frame 128: 0.9634\n",
      "  Frame 129: 0.9771\n",
      "  Frame 130: 0.9539\n",
      "  Frame 131: 0.9508\n",
      "  Frame 132: 0.9414\n",
      "  Frame 133: 0.9707\n",
      "  Frame 134: 0.9437\n",
      "  Frame 135: 0.9621\n",
      "  Frame 136: 0.9398\n",
      "  Frame 137: 0.9965\n",
      "  Frame 138: 0.9775\n",
      "  Frame 139: 0.9667\n",
      "  Frame 140: 0.9503\n",
      "  Frame 141: 0.9579\n",
      "  Frame 142: 0.9539\n",
      "  Frame 143: 0.9678\n",
      "  Frame 144: 0.9750\n",
      "  Frame 145: 0.9595\n",
      "  Frame 146: 0.9624\n",
      "  Frame 147: 0.8938\n",
      "  Frame 148: 0.9308\n",
      "  Frame 149: 0.9755\n",
      "  Frame 150: 0.9636\n",
      "  Frame 151: 0.8123\n",
      "  Frame 152: 0.7477\n",
      "  Frame 153: 0.9894\n",
      "  Frame 154: 0.9427\n",
      "  Frame 155: 0.9277\n",
      "  Frame 156: 0.8069\n",
      "  Frame 157: 0.8886\n",
      "  Frame 158: 0.9827\n",
      "  Frame 159: 0.9699\n",
      "  Frame 160: 0.9598\n",
      "  Frame 161: 0.9468\n",
      "  Frame 162: 0.9739\n",
      "  Frame 163: 0.9435\n",
      "  Frame 164: 0.9224\n",
      "  Frame 165: 0.8930\n",
      "  Frame 166: 0.9344\n",
      "  Frame 167: 0.9225\n",
      "  Frame 168: 0.9504\n",
      "  Frame 169: 0.9106\n",
      "  Frame 170: 0.9144\n",
      "  Frame 171: 0.8900\n",
      "  Frame 172: 0.9500\n",
      "  Frame 173: 0.9436\n",
      "  Frame 174: 0.9199\n",
      "  Frame 175: 0.8766\n",
      "  Frame 176: 0.8991\n",
      "  Frame 177: 0.9348\n",
      "  Frame 178: 0.8637\n",
      "  Frame 179: 0.9892\n",
      "  Frame 180: 0.8346\n",
      "  Frame 181: 0.9109\n",
      "  Frame 182: 0.8450\n",
      "  Frame 183: 0.9541\n",
      "  Frame 184: 0.9779\n",
      "  Frame 185: 0.9460\n",
      "  Frame 186: 0.9395\n",
      "  Frame 187: 0.9317\n",
      "  Frame 188: 0.7385\n",
      "  Frame 189: 0.8724\n",
      "  Frame 190: 0.6290\n",
      "  Frame 191: 0.7297\n",
      "  Frame 192: 0.8739\n",
      "  Frame 193: 0.9046\n",
      "  Frame 194: 0.8521\n",
      "  Frame 195: 0.8362\n",
      "  Frame 196: 0.9478\n",
      "  Frame 197: 0.8848\n",
      "  Frame 198: 0.8719\n",
      "  Frame 199: 0.8048\n",
      "  Frame 200: 0.8953\n",
      "  Frame 201: 0.8982\n",
      "  Frame 202: 0.8851\n",
      "  Frame 203: 0.8845\n",
      "  Frame 204: 0.9644\n",
      "  Frame 205: 0.9647\n",
      "  Frame 206: 0.6187\n",
      "  Frame 207: 0.9875\n",
      "  Frame 208: 0.7272\n",
      "  Frame 209: 0.5805\n",
      "  Frame 210: 0.9525\n",
      "  Frame 211: 0.8409\n",
      "  Frame 212: 0.7140\n",
      "  Frame 213: 0.8424\n",
      "  Frame 214: 0.7091\n",
      "  Frame 215: 0.9232\n",
      "  Frame 216: 0.9785\n",
      "  Frame 217: 0.8017\n",
      "  Frame 218: 0.9156\n",
      "  Frame 219: 0.7293\n",
      "  Frame 220: 0.9604\n",
      "  Frame 221: 0.9843\n",
      "  Frame 222: 0.9588\n",
      "  Frame 223: 0.8403\n",
      "  Frame 224: 0.7813\n",
      "  Frame 225: 0.9353\n",
      "  Frame 226: 0.6766\n",
      "  Frame 227: 0.7814\n",
      "  Frame 228: 0.9421\n",
      "  Frame 229: 0.7200\n",
      "  Frame 230: 0.6623\n",
      "\n",
      "Final Prediction: Fake (Average Confidence: 0.8695)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def evaluate_video_sequence(directory, loaded_model, input_size=(224, 224)):\n",
    "    frame_files = sorted([f for f in os.listdir(directory) if f.endswith(('.jpg', '.png'))])\n",
    "    \n",
    "    if not frame_files:\n",
    "        print(\"No image frames found in the directory.\")\n",
    "        return\n",
    "\n",
    "    frames = []\n",
    "    for filename in frame_files:\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Couldn't read {filename}, skipping.\")\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, input_size)\n",
    "        img = preprocess_input(img.astype(np.float32))\n",
    "        frames.append(img)\n",
    "\n",
    "    if not frames:\n",
    "        print(\"No valid frames to process.\")\n",
    "        return\n",
    "\n",
    "    input_batch = np.array(frames)\n",
    "\n",
    "    # Predict on each frame\n",
    "    predictions = loaded_model.predict(input_batch, verbose=0)  # shape: (num_frames, 2)\n",
    "    \n",
    "    # Print confidence for each frame\n",
    "    print(\"Per-frame predictions (Fake class confidence):\")\n",
    "    for i, pred in enumerate(predictions):\n",
    "        print(f\"  Frame {i + 1}: {pred[1]:.4f}\")\n",
    "\n",
    "    # Take average prediction for class 1 (e.g., \"Fake\")\n",
    "    confidence = np.mean(predictions[:, 1])\n",
    "    label = \"Fake\" if confidence >= 0.5 else \"Real\"\n",
    "    print(f\"\\nFinal Prediction: {label} (Average Confidence: {confidence:.4f})\")\n",
    "\n",
    "# Usage example (ensure your model is loaded):\n",
    "# loaded_model = load_model(\"deepfake_model.h5\")\n",
    "evaluate_video_sequence(\"frames\", loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory cleared!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    # Clear TensorFlow session\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Collect garbage\n",
    "    gc.collect()\n",
    "    \n",
    "    # Reset the default graph\n",
    "    ops.reset_default_graph()\n",
    "\n",
    "    print(\"GPU memory cleared!\")\n",
    "\n",
    "# Call this function when you need to clear the memory\n",
    "clear_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TensorFlow GPU memory cleared.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Reset session and clear memory\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Optional: run garbage collector\n",
    "gc.collect()\n",
    "\n",
    "print(\"✅ TensorFlow GPU memory cleared.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
