{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing import image \n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Input paths\n",
    "input_base_path = r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\BothDatasets\\combined_dataset\"\n",
    "real_videos_path = os.path.join(input_base_path, \"real\")\n",
    "fake_videos_path = os.path.join(input_base_path, \"fake\")\n",
    "\n",
    "# Output paths\n",
    "output_base_path = r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\BothDatasets\\FramesExtracted\"\n",
    "real_output_path = os.path.join(output_base_path, \"RealFrames\")\n",
    "fake_output_path = os.path.join(output_base_path, \"FakeFrames\")\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(real_output_path, exist_ok=True)\n",
    "os.makedirs(fake_output_path, exist_ok=True)\n",
    "\n",
    "def extract_frames(video_path, output_folder, video_name, num_frames=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    if total_frames < num_frames:\n",
    "        print(f\"Skipping {video_name}: Not enough frames.\")\n",
    "        cap.release()\n",
    "        return\n",
    "\n",
    "    frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)\n",
    "    saved = 0\n",
    "    for i in range(total_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if i in frame_indices:\n",
    "            frame_filename = f\"{video_name}_frame{saved+1:02d}.jpg\"\n",
    "            frame_path = os.path.join(output_folder, frame_filename)\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            saved += 1\n",
    "    cap.release()\n",
    "\n",
    "# Process real videos\n",
    "print(\"Processing real videos...\")\n",
    "for video_file in os.listdir(real_videos_path):\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(real_videos_path, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        extract_frames(video_path, real_output_path, video_name)\n",
    "\n",
    "# Process fake videos, but only 590 of them\n",
    "print(\"Processing fake videos (limit: 1090 videos)...\")\n",
    "fake_video_count = 0\n",
    "fake_video_limit = 1090\n",
    "\n",
    "for video_file in os.listdir(fake_videos_path):\n",
    "    if fake_video_count >= fake_video_limit:\n",
    "        break\n",
    "    if video_file.endswith(\".mp4\"):\n",
    "        video_path = os.path.join(fake_videos_path, video_file)\n",
    "        video_name = os.path.splitext(video_file)[0]\n",
    "        extract_frames(video_path, fake_output_path, video_name)\n",
    "        fake_video_count += 1\n",
    "\n",
    "print(\"Done extracting frames.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✱] Cleared existing files in 'frames'\n",
      "[✓] Saved frames/face_0_0.jpg\n",
      "[✓] Saved frames/face_0_1.jpg\n",
      "[✓] Saved frames/face_20_0.jpg\n",
      "[✓] Saved frames/face_20_1.jpg\n",
      "[✓] Saved frames/face_40_0.jpg\n",
      "[✓] Saved frames/face_60_0.jpg\n",
      "[✓] Saved frames/face_80_0.jpg\n",
      "[✓] Saved frames/face_80_1.jpg\n",
      "[✓] Saved frames/face_100_0.jpg\n",
      "[✓] Saved frames/face_140_0.jpg\n",
      "[✓] Saved frames/face_160_0.jpg\n",
      "[✓] Saved frames/face_160_1.jpg\n",
      "[✓] Saved frames/face_180_0.jpg\n",
      "[✓] Saved frames/face_180_1.jpg\n",
      "[✓] Saved frames/face_200_0.jpg\n",
      "[✓] Saved frames/face_200_1.jpg\n",
      "[✓] Saved frames/face_200_2.jpg\n",
      "[✓] Saved frames/face_220_0.jpg\n",
      "[✓] Saved frames/face_220_1.jpg\n",
      "[✓] Saved frames/face_240_0.jpg\n",
      "[✓] Saved frames/face_300_0.jpg\n",
      "\n",
      "Done: 21 face crops saved.\n",
      "No faces detected, removing: face_0_0.jpg\n",
      "No faces detected, removing: face_100_0.jpg\n",
      "No faces detected, removing: face_140_0.jpg\n",
      "No faces detected, removing: face_160_0.jpg\n",
      "No faces detected, removing: face_200_0.jpg\n",
      "No faces detected, removing: face_220_0.jpg\n",
      "No faces detected, removing: face_240_0.jpg\n",
      "No faces detected, removing: face_80_0.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import cv2\n",
    "\n",
    "# Path to the folder containing frames\n",
    "frames_directory = r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\notebooks\\frames\"\n",
    "\n",
    "# Load Haar cascade face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def FrameCapture(video_path, output_dir=\"frames\", frame_skip=20, min_face_size=60):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Cannot open video.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    frame_count = 0\n",
    "    saved_faces = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % frame_skip == 0:\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            faces = face_cascade.detectMultiScale(\n",
    "                gray,\n",
    "                scaleFactor=1.1,\n",
    "                minNeighbors=6,\n",
    "                minSize=(min_face_size, min_face_size)\n",
    "            )\n",
    "\n",
    "            for i, (x, y, w, h) in enumerate(faces):\n",
    "                aspect_ratio = w / float(h)\n",
    "                if aspect_ratio < 0.75 or aspect_ratio > 1.33:\n",
    "                    continue\n",
    "\n",
    "                face = frame[y:y+h, x:x+w]\n",
    "                brightness = face.mean()\n",
    "                if brightness < 40:\n",
    "                    continue\n",
    "\n",
    "                filename = f\"{output_dir}/face_{frame_count}_{i}.jpg\"\n",
    "                cv2.imwrite(filename, face)\n",
    "\n",
    "                print(f\"[✓] Saved {filename}\")\n",
    "                saved_faces += 1\n",
    "\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"\\nDone: {saved_faces} face crops saved.\")\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.gif'))\n",
    "\n",
    "def process_file(path, output_dir=\"frames\", min_face_size=60):\n",
    "    # Clear existing frames\n",
    "    if os.path.exists(output_dir):\n",
    "        for f in os.listdir(output_dir):\n",
    "            file_path = os.path.join(output_dir, f)\n",
    "            if os.path.isfile(file_path):\n",
    "                os.remove(file_path)\n",
    "        print(f\"[✱] Cleared existing files in '{output_dir}'\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if is_image_file(path):\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            print(\"Error: Cannot read image.\")\n",
    "            return\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=6,\n",
    "            minSize=(min_face_size, min_face_size)\n",
    "        )\n",
    "\n",
    "        total_saved = 0\n",
    "        for i, (x, y, w, h) in enumerate(faces):\n",
    "            aspect_ratio = w / float(h)\n",
    "            if aspect_ratio < 0.75 or aspect_ratio > 1.33:\n",
    "                continue\n",
    "\n",
    "            face = img[y:y+h, x:x+w]\n",
    "            brightness = face.mean()\n",
    "            if brightness < 40:\n",
    "                continue\n",
    "\n",
    "            # Save 30 copies of the face\n",
    "            for j in range(30):\n",
    "                filename = f\"{output_dir}/image_face_{i}_copy_{j}.jpg\"\n",
    "                cv2.imwrite(filename, face)\n",
    "\n",
    "                print(f\"[✓] Saved {filename}\")\n",
    "                total_saved += 1\n",
    "\n",
    "        print(f\"[→] Detected {len(faces)} valid face(s)\")\n",
    "        print(f\"[→] Saved {total_saved} face crops (30 per face)\")\n",
    "    else:\n",
    "        FrameCapture(path)\n",
    "\n",
    "\n",
    "def remove_non_face_and_duplicate_frames(directory):\n",
    "    # Set to store unique hashes of images\n",
    "    seen_hashes = set()\n",
    "\n",
    "    # List all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "\n",
    "    # Iterate over all files\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "\n",
    "        # Only consider image files (you can extend this list if needed)\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "            try:\n",
    "                # Open image and compute hash\n",
    "                image = Image.open(file_path)\n",
    "                image_hash = imagehash.average_hash(image)\n",
    "\n",
    "                # Detect faces in the image\n",
    "                img_cv = cv2.imread(file_path)\n",
    "                gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "                faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "                # If no faces are detected, remove the image\n",
    "                if len(faces) == 0:\n",
    "                    print(f\"No faces detected, removing: {file}\")\n",
    "                    os.remove(file_path)\n",
    "                else:\n",
    "                    # Check if the image hash is already in the set (duplicate)\n",
    "                    if image_hash in seen_hashes:\n",
    "                        print(f\"Duplicate found and removing: {file}\")\n",
    "                        os.remove(file_path)\n",
    "                    else:\n",
    "                        # Otherwise, add the hash to the set (unique image with face)\n",
    "                        seen_hashes.add(image_hash)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "process_file(r\"C:\\Users\\creat\\Desktop\\Testing videos\\elonmusk.mp4\")\n",
    "remove_non_face_and_duplicate_frames(frames_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# Load your saved Xception-based model\n",
    "loaded_model = load_model(r\"C:\\Users\\creat\\Desktop\\semesters\\7th semester\\deepfake_fyp1\\models\\NewXception-16Epochs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-frame predictions (Fake class confidence):\n",
      "  Frame 1: 0.6796\n",
      "  Frame 2: 0.8927\n",
      "  Frame 3: 0.6884\n",
      "  Frame 4: 0.8940\n",
      "  Frame 5: 0.8741\n",
      "  Frame 6: 0.7496\n",
      "  Frame 7: 0.8863\n",
      "  Frame 8: 0.6037\n",
      "  Frame 9: 0.6999\n",
      "  Frame 10: 0.6861\n",
      "  Frame 11: 0.6403\n",
      "  Frame 12: 0.7086\n",
      "  Frame 13: 0.5999\n",
      "\n",
      "Final Prediction: Fake (Average Confidence: 0.7387)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def evaluate_video_sequence(directory, loaded_model, input_size=(224, 224)):\n",
    "    frame_files = sorted([f for f in os.listdir(directory) if f.endswith(('.jpg', '.png'))])\n",
    "    \n",
    "    if not frame_files:\n",
    "        print(\"No image frames found in the directory.\")\n",
    "        return\n",
    "\n",
    "    frames = []\n",
    "    for filename in frame_files:\n",
    "        img_path = os.path.join(directory, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Couldn't read {filename}, skipping.\")\n",
    "            continue\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, input_size)\n",
    "        img = preprocess_input(img.astype(np.float32))\n",
    "        frames.append(img)\n",
    "\n",
    "    if not frames:\n",
    "        print(\"No valid frames to process.\")\n",
    "        return\n",
    "\n",
    "    input_batch = np.array(frames)\n",
    "\n",
    "    # Predict on each frame\n",
    "    predictions = loaded_model.predict(input_batch, verbose=0)  # shape: (num_frames, 2)\n",
    "    \n",
    "    # Print confidence for each frame\n",
    "    print(\"Per-frame predictions (Fake class confidence):\")\n",
    "    for i, pred in enumerate(predictions):\n",
    "        print(f\"  Frame {i + 1}: {pred[1]:.4f}\")\n",
    "\n",
    "    # Take average prediction for class 1 (e.g., \"Fake\")\n",
    "    confidence = np.mean(predictions[:, 1])\n",
    "    label = \"Fake\" if confidence >= 0.5 else \"Real\"\n",
    "    print(f\"\\nFinal Prediction: {label} (Average Confidence: {confidence:.4f})\")\n",
    "\n",
    "# Usage example (ensure your model is loaded):\n",
    "# loaded_model = load_model(\"deepfake_model.h5\")\n",
    "evaluate_video_sequence(\"frames\", loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory cleared!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "def clear_gpu_memory():\n",
    "    # Clear TensorFlow session\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # Collect garbage\n",
    "    gc.collect()\n",
    "    \n",
    "    # Reset the default graph\n",
    "    ops.reset_default_graph()\n",
    "\n",
    "    print(\"GPU memory cleared!\")\n",
    "\n",
    "# Call this function when you need to clear the memory\n",
    "clear_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TensorFlow GPU memory cleared.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import gc\n",
    "\n",
    "# Reset session and clear memory\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Optional: run garbage collector\n",
    "gc.collect()\n",
    "\n",
    "print(\"✅ TensorFlow GPU memory cleared.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
